#!/usr/bin/env python3
"""
ä»·å·®æ•°æ®åˆ†æè„šæœ¬ - analyze.py
åˆ†æmark.pyè®°å½•çš„ä»·å·®æ•°æ®ï¼Œå‘ç°å¥—åˆ©æœºä¼šå’Œè§„å¾‹
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
import argparse
import glob
from datetime import datetime
import sys

class SpreadAnalyzer:
    """ä»·å·®æ•°æ®åˆ†æå™¨"""

    def __init__(self, data_dir: str = "spread_data"):
        self.data_dir = Path(data_dir)
        self.data = {}

        # è®¾ç½®ä¸­æ–‡å­—ä½“å’Œæ ·å¼
        plt.rcParams['font.sans-serif'] = ['Arial', 'SimHei']
        plt.rcParams['axes.unicode_minus'] = False
        sns.set_style("whitegrid")

        print("ğŸ“Š ä»·å·®æ•°æ®åˆ†æå™¨åˆå§‹åŒ–å®Œæˆ")

    def load_data(self, symbol: str = None, days: int = None):
        """åŠ è½½æ•°æ®æ–‡ä»¶"""
        try:
            print(f"ğŸ“‚ ä» {self.data_dir} åŠ è½½æ•°æ®...")

            # æŸ¥æ‰¾CSVæ–‡ä»¶
            if symbol:
                pattern = f"spread_{symbol}_*.csv"
            else:
                pattern = "spread_*.csv"

            csv_files = list(self.data_dir.glob(pattern))

            if not csv_files:
                print(f"âŒ æœªæ‰¾åˆ°åŒ¹é…çš„æ•°æ®æ–‡ä»¶: {pattern}")
                return False

            print(f"ğŸ“ å‘ç° {len(csv_files)} ä¸ªæ•°æ®æ–‡ä»¶")

            # åŠ è½½æ‰€æœ‰CSVæ–‡ä»¶
            all_data = []
            for file in csv_files:
                print(f"ğŸ“– è¯»å–: {file.name}")
                df = pd.read_csv(file)
                df['datetime'] = pd.to_datetime(df['datetime'])
                all_data.append(df)

            # åˆå¹¶æ•°æ®
            if all_data:
                combined_data = pd.concat(all_data, ignore_index=True)
                combined_data = combined_data.sort_values('datetime')

                # æŒ‰å¤©æ•°è¿‡æ»¤
                if days:
                    cutoff_date = combined_data['datetime'].max() - pd.Timedelta(days=days)
                    combined_data = combined_data[combined_data['datetime'] >= cutoff_date]

                # æŒ‰äº¤æ˜“å¯¹åˆ†ç»„
                for sym in combined_data['symbol'].unique():
                    self.data[sym] = combined_data[combined_data['symbol'] == sym].copy()

                total_records = sum(len(df) for df in self.data.values())
                print(f"âœ… åŠ è½½å®Œæˆ: {total_records} æ¡è®°å½•")
                print(f"ğŸ“Š äº¤æ˜“å¯¹: {list(self.data.keys())}")

                return True

        except Exception as e:
            print(f"âŒ åŠ è½½æ•°æ®å¤±è´¥: {e}")
            return False

    def basic_statistics(self):
        """åŸºç¡€ç»Ÿè®¡åˆ†æ"""
        print("\n" + "="*50)
        print("ğŸ“Š åŸºç¡€ç»Ÿè®¡åˆ†æ")
        print("="*50)

        for symbol, df in self.data.items():
            print(f"\nğŸ”¸ {symbol} ç»Ÿè®¡ä¿¡æ¯:")
            print(f"   è®°å½•æ¡æ•°: {len(df):,}")
            print(f"   æ—¶é—´èŒƒå›´: {df['datetime'].min()} ~ {df['datetime'].max()}")

            # ä»·å·®ç»Ÿè®¡
            spread_cols = ['spread_1', 'spread_2', 'best_spread']
            spread_stats = df[spread_cols].describe()

            print(f"\n   ä»·å·®ç»Ÿè®¡:")
            print(f"   æ–¹å‘1 (Aä¹°â†’Bå–): å‡å€¼{spread_stats.loc['mean', 'spread_1']:.2f}, "
                  f"æ ‡å‡†å·®{spread_stats.loc['std', 'spread_1']:.2f}")
            print(f"   æ–¹å‘2 (Bä¹°â†’Aå–): å‡å€¼{spread_stats.loc['mean', 'spread_2']:.2f}, "
                  f"æ ‡å‡†å·®{spread_stats.loc['std', 'spread_2']:.2f}")
            print(f"   æœ€ä½³ä»·å·®: å‡å€¼{spread_stats.loc['mean', 'best_spread']:.2f}, "
                  f"æ ‡å‡†å·®{spread_stats.loc['std', 'best_spread']:.2f}")

            # å¥—åˆ©æœºä¼šç»Ÿè®¡
            profitable_1 = (df['spread_1'] > 1.0).sum()
            profitable_2 = (df['spread_2'] > 1.0).sum()
            total_profitable = profitable_1 + profitable_2

            print(f"\n   å¥—åˆ©æœºä¼š (ä»·å·®>1ç¾å…ƒ):")
            print(f"   Aä¹°â†’Bå–: {profitable_1} æ¬¡ ({profitable_1/len(df)*100:.1f}%)")
            print(f"   Bä¹°â†’Aå–: {profitable_2} æ¬¡ ({profitable_2/len(df)*100:.1f}%)")
            print(f"   æ€»è®¡: {total_profitable} æ¬¡ ({total_profitable/len(df)*100:.1f}%)")

    def spread_distribution(self):
        """ä»·å·®åˆ†å¸ƒåˆ†æ"""
        print("\n" + "="*50)
        print("ğŸ“ˆ ä»·å·®åˆ†å¸ƒåˆ†æ")
        print("="*50)

        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        fig.suptitle('Spread Distribution Analysis', fontsize=16)

        for i, (symbol, df) in enumerate(self.data.items()):
            row = i // 2
            col = i % 2

            if row < 2 and col < 2:
                ax = axes[row, col]

                # ç»˜åˆ¶ä»·å·®åˆ†å¸ƒç›´æ–¹å›¾
                ax.hist(df['spread_1'], bins=50, alpha=0.7, label='Aä¹°â†’Bå–', color='blue')
                ax.hist(df['spread_2'], bins=50, alpha=0.7, label='Bä¹°â†’Aå–', color='red')
                ax.axvline(x=1.0, color='green', linestyle='--', label='ç›ˆåˆ©çº¿(+1)')
                ax.axvline(x=-1.0, color='green', linestyle='--')
                ax.set_title(f'{symbol} Spread Distribution')
                ax.set_xlabel('Spread (USD)')
                ax.set_ylabel('Frequency')
                ax.legend()
                ax.grid(True, alpha=0.3)

        plt.tight_layout()
        plt.savefig(self.data_dir / 'spread_distribution.png', dpi=300, bbox_inches='tight')
        print(f"ğŸ’¾ ä»·å·®åˆ†å¸ƒå›¾ä¿å­˜: {self.data_dir / 'spread_distribution.png'}")

    def time_series_analysis(self):
        """æ—¶é—´åºåˆ—åˆ†æ"""
        print("\n" + "="*50)
        print("â° æ—¶é—´åºåˆ—åˆ†æ")
        print("="*50)

        fig, axes = plt.subplots(len(self.data), 1, figsize=(15, 6*len(self.data)))
        if len(self.data) == 1:
            axes = [axes]

        for i, (symbol, df) in enumerate(self.data.items()):
            ax = axes[i]

            # é‡é‡‡æ ·ä¸ºåˆ†é’Ÿæ•°æ®
            df_resampled = df.set_index('datetime').resample('1T').mean()

            ax.plot(df_resampled.index, df_resampled['spread_1'],
                   label='Aä¹°â†’Bå–', alpha=0.8, linewidth=1)
            ax.plot(df_resampled.index, df_resampled['spread_2'],
                   label='Bä¹°â†’Aå–', alpha=0.8, linewidth=1)
            ax.axhline(y=1.0, color='green', linestyle='--', alpha=0.7, label='ç›ˆåˆ©çº¿')
            ax.axhline(y=-1.0, color='green', linestyle='--', alpha=0.7)
            ax.fill_between(df_resampled.index, 1.0, df_resampled['spread_1'],
                           where=(df_resampled['spread_1'] > 1.0),
                           alpha=0.3, color='green', label='ç›ˆåˆ©åŒºåŸŸ1')
            ax.fill_between(df_resampled.index, -1.0, df_resampled['spread_2'],
                           where=(df_resampled['spread_2'] > 1.0),
                           alpha=0.3, color='red', label='ç›ˆåˆ©åŒºåŸŸ2')

            ax.set_title(f'{symbol} Spread Time Series')
            ax.set_xlabel('Time')
            ax.set_ylabel('Spread (USD)')
            ax.legend()
            ax.grid(True, alpha=0.3)

        plt.tight_layout()
        plt.savefig(self.data_dir / 'spread_timeseries.png', dpi=300, bbox_inches='tight')
        print(f"ğŸ’¾ æ—¶é—´åºåˆ—å›¾ä¿å­˜: {self.data_dir / 'spread_timeseries.png'}")

    def arbitrage_opportunities(self, min_spread: float = 1.0):
        """å¥—åˆ©æœºä¼šåˆ†æ"""
        print(f"\n" + "="*50)
        print(f"ğŸ’° å¥—åˆ©æœºä¼šåˆ†æ (æœ€å°ä»·å·®: {min_spread})")
        print("="*50)

        for symbol, df in self.data.items():
            print(f"\nğŸ”¸ {symbol} å¥—åˆ©æœºä¼š:")

            # æ–¹å‘1å¥—åˆ©æœºä¼š
            opp_1 = df[df['spread_1'] > min_spread].copy()
            if len(opp_1) > 0:
                print(f"   Aä¹°â†’Bå–å¥—åˆ©:")
                print(f"     æœºä¼šæ¬¡æ•°: {len(opp_1)}")
                print(f"     å¹³å‡ä»·å·®: {opp_1['spread_1'].mean():.2f}")
                print(f"     æœ€å¤§ä»·å·®: {opp_1['spread_1'].max():.2f}")
                print(f"     æŒç»­æ—¶é—´: å¹³å‡ {self._calculate_duration(opp_1):.1f}ç§’")

            # æ–¹å‘2å¥—åˆ©æœºä¼š
            opp_2 = df[df['spread_2'] > min_spread].copy()
            if len(opp_2) > 0:
                print(f"   Bä¹°â†’Aå–å¥—åˆ©:")
                print(f"     æœºä¼šæ¬¡æ•°: {len(opp_2)}")
                print(f"     å¹³å‡ä»·å·®: {opp_2['spread_2'].mean():.2f}")
                print(f"     æœ€å¤§ä»·å·®: {opp_2['spread_2'].max():.2f}")
                print(f"     æŒç»­æ—¶é—´: å¹³å‡ {self._calculate_duration(opp_2):.1f}ç§’")

            # ä¿å­˜å¥—åˆ©æœºä¼šè¯¦æƒ…
            all_opportunities = pd.concat([
                opp_1[['datetime', 'spread_1']].rename(columns={'spread_1': 'spread'}).assign(direction='Aä¹°â†’Bå–'),
                opp_2[['datetime', 'spread_2']].rename(columns={'spread_2': 'spread'}).assign(direction='Bä¹°â†’Aå–')
            ]).sort_values('datetime')

            if len(all_opportunities) > 0:
                filename = self.data_dir / f'arbitrage_opportunities_{symbol}.csv'
                all_opportunities.to_csv(filename, index=False)
                print(f"   ğŸ’¾ å¥—åˆ©æœºä¼šè¯¦æƒ…ä¿å­˜: {filename}")

    def _calculate_duration(self, df):
        """è®¡ç®—å¥—åˆ©æœºä¼šå¹³å‡æŒç»­æ—¶é—´"""
        if len(df) <= 1:
            return 0

        durations = []
        current_start = df.iloc[0]['datetime']

        for i in range(1, len(df)):
            time_gap = (df.iloc[i]['datetime'] - df.iloc[i-1]['datetime']).total_seconds()
            if time_gap > 10:  # è¶…è¿‡10ç§’è®¤ä¸ºæ˜¯æ–°çš„æœºä¼š
                durations.append((df.iloc[i-1]['datetime'] - current_start).total_seconds())
                current_start = df.iloc[i]['datetime']

        # æ·»åŠ æœ€åä¸€ä¸ªæœºä¼šçš„æŒç»­æ—¶é—´
        durations.append((df.iloc[-1]['datetime'] - current_start).total_seconds())

        return np.mean(durations) if durations else 0

    def correlation_analysis(self):
        """ç›¸å…³æ€§åˆ†æ"""
        print(f"\n" + "="*50)
        print("ğŸ”— ç›¸å…³æ€§åˆ†æ")
        print("="*50)

        if len(self.data) < 2:
            print("éœ€è¦è‡³å°‘2ä¸ªäº¤æ˜“å¯¹è¿›è¡Œç›¸å…³æ€§åˆ†æ")
            return

        # åˆå¹¶æ‰€æœ‰æ•°æ®è¿›è¡Œç›¸å…³æ€§åˆ†æ
        correlation_data = {}
        base_time = None

        for symbol, df in self.data.items():
            # é‡é‡‡æ ·ä¸ºåˆ†é’Ÿæ•°æ®
            df_resampled = df.set_index('datetime').resample('1T').mean()
            correlation_data[f'{symbol}_spread_1'] = df_resampled['spread_1']
            correlation_data[f'{symbol}_spread_2'] = df_resampled['spread_2']
            correlation_data[f'{symbol}_best'] = df_resampled['best_spread']

        corr_df = pd.DataFrame(correlation_data)
        correlation_matrix = corr_df.corr()

        # ç»˜åˆ¶ç›¸å…³æ€§çƒ­åŠ›å›¾
        plt.figure(figsize=(12, 10))
        sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0,
                   square=True, linewidths=0.5)
        plt.title('Spread Correlation Matrix')
        plt.tight_layout()
        plt.savefig(self.data_dir / 'correlation_matrix.png', dpi=300, bbox_inches='tight')
        print(f"ğŸ’¾ ç›¸å…³æ€§çŸ©é˜µå›¾ä¿å­˜: {self.data_dir / 'correlation_matrix.png'}")

        # æ‰“å°å…³é”®ç›¸å…³æ€§
        print("\nå…³é”®ç›¸å…³æ€§ç³»æ•°:")
        symbols = list(self.data.keys())
        if len(symbols) >= 2:
            for i in range(len(symbols)):
                for j in range(i+1, len(symbols)):
                    corr_coef = correlation_matrix.loc[f'{symbols[i]}_best', f'{symbols[j]}_best']
                    print(f"   {symbols[i]} vs {symbols[j]}: {corr_coef:.3f}")

    def generate_report(self):
        """ç”Ÿæˆåˆ†ææŠ¥å‘Š"""
        print(f"\n" + "="*50)
        print("ğŸ“‹ ç”Ÿæˆåˆ†ææŠ¥å‘Š")
        print("="*50)

        report_file = self.data_dir / 'analysis_report.txt'

        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(f"ä»·å·®æ•°æ®åˆ†ææŠ¥å‘Š\n")
            f.write(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"="*50 + "\n\n")

            for symbol, df in self.data.items():
                f.write(f"{symbol} åˆ†æç»“æœ:\n")
                f.write(f"-"*30 + "\n")

                # åŸºç¡€ç»Ÿè®¡
                f.write(f"æ•°æ®æ¦‚å†µ:\n")
                f.write(f"  è®°å½•æ¡æ•°: {len(df):,}\n")
                f.write(f"  æ—¶é—´èŒƒå›´: {df['datetime'].min()} ~ {df['datetime'].max()}\n")

                # ä»·å·®ç»Ÿè®¡
                f.write(f"\nä»·å·®ç»Ÿè®¡:\n")
                f.write(f"  æ–¹å‘1å‡å€¼: {df['spread_1'].mean():.2f} Â± {df['spread_1'].std():.2f}\n")
                f.write(f"  æ–¹å‘2å‡å€¼: {df['spread_2'].mean():.2f} Â± {df['spread_2'].std():.2f}\n")
                f.write(f"  æœ€ä½³ä»·å·®å‡å€¼: {df['best_spread'].mean():.2f} Â± {df['best_spread'].std():.2f}\n")

                # å¥—åˆ©æœºä¼š
                profitable_1 = (df['spread_1'] > 1.0).sum()
                profitable_2 = (df['spread_2'] > 1.0).sum()
                f.write(f"\nå¥—åˆ©æœºä¼š (>1ç¾å…ƒ):\n")
                f.write(f"  æ–¹å‘1: {profitable_1} æ¬¡ ({profitable_1/len(df)*100:.1f}%)\n")
                f.write(f"  æ–¹å‘2: {profitable_2} æ¬¡ ({profitable_2/len(df)*100:.1f}%)\n")
                f.write(f"  æ€»è®¡: {profitable_1 + profitable_2} æ¬¡ ({(profitable_1 + profitable_2)/len(df)*100:.1f}%)\n")

                f.write(f"\n" + "="*50 + "\n\n")

        print(f"ğŸ’¾ åˆ†ææŠ¥å‘Šä¿å­˜: {report_file}")

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='ä»·å·®æ•°æ®åˆ†æå·¥å…·')
    parser.add_argument('--data-dir', default='spread_data', help='æ•°æ®ç›®å½•è·¯å¾„')
    parser.add_argument('--symbol', help='æŒ‡å®šåˆ†æçš„äº¤æ˜“å¯¹')
    parser.add_argument('--days', type=int, help='åˆ†ææœ€è¿‘Nå¤©çš„æ•°æ®')
    parser.add_argument('--min-spread', type=float, default=1.0, help='æœ€å°å¥—åˆ©ä»·å·®')

    args = parser.parse_args()

    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘      ä»·å·®æ•°æ®åˆ†æå™¨ - analyze.py       â•‘
â•‘        å¥—åˆ©æœºä¼šä¸è§„å¾‹åˆ†æ              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)

    try:
        analyzer = SpreadAnalyzer(args.data_dir)

        # åŠ è½½æ•°æ®
        if not analyzer.load_data(symbol=args.symbol, days=args.days):
            return

        # æ‰§è¡Œå„ç§åˆ†æ
        analyzer.basic_statistics()
        analyzer.spread_distribution()
        analyzer.time_series_analysis()
        analyzer.arbitrage_opportunities(min_spread=args.min_spread)
        analyzer.correlation_analysis()
        analyzer.generate_report()

        print(f"\nâœ… åˆ†æå®Œæˆï¼ç»“æœä¿å­˜åœ¨: {analyzer.data_dir}")

    except Exception as e:
        print(f"âŒ åˆ†æå¤±è´¥: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()